{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.data <- read.csv(file.path(\"..\", \"data\", \"training_data.csv\"))\n",
    "test.data <- read.csv(file.path(\"..\", \"data\", \"test_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "numeric.intensity <- as.numeric(train.data$Intensity)\n",
    "x <- train.data[, -c(2,3)]\n",
    "x$Intensity <- numeric.intensity\n",
    "n.before <- dim(x)[2] #numbers of predictors before the reduction\n",
    "idx.zero.var <- apply(x, 2, var) == 0\n",
    "x <- x[,!idx.zero.var]\n",
    "y <- train.data$VALENCE.PLEASANTNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for input variables with zero variance (without the varible Intensity)\n",
    "set.seed(100)\n",
    "x <- train.data[, -c(1,2,3)]\n",
    "\n",
    "idx.zero.var <- apply(x, 2, var) == 0\n",
    "x <- x[,!idx.zero.var]\n",
    "\n",
    "\n",
    "#attache Intensity as factor\n",
    "x$Intensity <- as.factor(train.data$Intensity)\n",
    "\n",
    "data <- x\n",
    "data$VALENCE.PLEASANTNESS <- train.data$VALENCE.PLEASANTNESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "#train and validation indexes\n",
    "len <- length(x[,1])\n",
    "idx.train <- sample(1:len, 2*len/3)\n",
    "\n",
    "#xgboost does not accept data frames therefore we will first convert the data into ordinary matrices\n",
    "library(xgboost)\n",
    "library(Matrix)\n",
    "train.x <- sparse.model.matrix(VALENCE.PLEASANTNESS ~ . -1, data = data[idx.train,])\n",
    "validation.x <- sparse.model.matrix(VALENCE.PLEASANTNESS ~ . -1, data = data[-idx.train,])\n",
    "train.y <- data$VALENCE.PLEASANTNESS[idx.train]\n",
    "validation.y <- data$VALENCE.PLEASANTNESS[-idx.train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost.heart <- xgboost(train.x, label = train.y,\n",
    "                      objective = \"reg:squarederror\",\n",
    "                      eta = 0.01,\n",
    "                      max_depth = 2,\n",
    "                      nround = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.train <- predict(boost.heart, train.x)\n",
    "prediction.validation <- predict(boost.heart, validation.x)\n",
    "MSE.train <- mean((prediction.train - train.y)^2)\n",
    "MSE.validation <- mean((prediction.validation - validation.y)^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "300.145837255573"
      ],
      "text/latex": [
       "300.145837255573"
      ],
      "text/markdown": [
       "300.145837255573"
      ],
      "text/plain": [
       "[1] 300.1458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "439.258313515555"
      ],
      "text/latex": [
       "439.258313515555"
      ],
      "text/markdown": [
       "439.258313515555"
      ],
      "text/plain": [
       "[1] 439.2583"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE.train\n",
    "MSE.validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>complexity.from.pubmed</th><th scope=col>MW</th><th scope=col>AMW</th><th scope=col>Sv</th><th scope=col>Se</th><th scope=col>Sp</th><th scope=col>Si</th><th scope=col>Mv</th><th scope=col>Me</th><th scope=col>Mp</th><th scope=col>...</th><th scope=col>Depressant.50</th><th scope=col>Hypertens.80</th><th scope=col>Hypertens.50</th><th scope=col>Hypnotic.80</th><th scope=col>Hypnotic.50</th><th scope=col>Neoplastic.80</th><th scope=col>Neoplastic.50</th><th scope=col>Infective.80</th><th scope=col>Infective.50</th><th scope=col>Intensity</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>302.0 </td><td>208.33</td><td>5.952 </td><td>19.698</td><td>34.491</td><td>21.523</td><td>39.571</td><td>0.563 </td><td>0.985 </td><td>0.615 </td><td>...   </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 72.6 </td><td>122.18</td><td>6.431 </td><td>11.349</td><td>18.745</td><td>12.261</td><td>21.285</td><td>0.597 </td><td>0.987 </td><td>0.645 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>259.0 </td><td>242.29</td><td>7.572 </td><td>20.832</td><td>32.167</td><td>21.693</td><td>35.535</td><td>0.651 </td><td>1.005 </td><td>0.678 </td><td>...   </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>1     </td><td>1     </td><td>0     </td><td>1     </td><td>1     </td><td>0     </td></tr>\n",
       "\t<tr><td> 56.6 </td><td> 88.12</td><td>6.294 </td><td> 7.537</td><td>14.189</td><td> 7.955</td><td>16.080</td><td>0.538 </td><td>1.014 </td><td>0.568 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 84.7 </td><td>136.21</td><td>6.191 </td><td>12.876</td><td>21.629</td><td>14.023</td><td>24.701</td><td>0.585 </td><td>0.983 </td><td>0.637 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>160.0 </td><td>192.28</td><td>6.409 </td><td>17.644</td><td>29.723</td><td>19.000</td><td>33.740</td><td>0.588 </td><td>0.991 </td><td>0.633 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>116.0 </td><td>170.22</td><td>7.401 </td><td>15.349</td><td>22.745</td><td>16.261</td><td>25.285</td><td>0.667 </td><td>0.989 </td><td>0.707 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 25.0 </td><td>114.26</td><td>4.395 </td><td>12.741</td><td>24.952</td><td>14.853</td><td>29.737</td><td>0.490 </td><td>0.960 </td><td>0.571 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>355.0 </td><td>268.30</td><td>7.666 </td><td>21.304</td><td>36.025</td><td>21.614</td><td>39.950</td><td>0.609 </td><td>1.029 </td><td>0.618 </td><td>...   </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>1     </td><td>1     </td><td>1     </td><td>1     </td><td>1     </td><td>1     </td></tr>\n",
       "\t<tr><td> 68.4 </td><td>152.26</td><td>9.516 </td><td> 9.911</td><td>16.342</td><td>11.250</td><td>17.920</td><td>0.619 </td><td>1.021 </td><td>0.703 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>155.0 </td><td>148.17</td><td>7.798 </td><td>12.537</td><td>19.189</td><td>12.955</td><td>21.080</td><td>0.660 </td><td>1.010 </td><td>0.682 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 25.1 </td><td> 88.17</td><td>4.898 </td><td> 8.876</td><td>17.629</td><td>10.023</td><td>20.701</td><td>0.493 </td><td>0.979 </td><td>0.557 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 35.2 </td><td>102.20</td><td>4.867 </td><td>10.402</td><td>20.513</td><td>11.784</td><td>24.116</td><td>0.495 </td><td>0.977 </td><td>0.561 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>101.0 </td><td>134.19</td><td>6.710 </td><td>12.349</td><td>19.745</td><td>13.261</td><td>22.285</td><td>0.617 </td><td>0.987 </td><td>0.663 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>114.0 </td><td>146.16</td><td>7.308 </td><td>11.493</td><td>20.727</td><td>11.625</td><td>22.914</td><td>0.575 </td><td>1.036 </td><td>0.581 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 52.5 </td><td>130.26</td><td>4.824 </td><td>13.456</td><td>26.280</td><td>15.307</td><td>30.946</td><td>0.498 </td><td>0.973 </td><td>0.567 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>112.0 </td><td>160.24</td><td>5.935 </td><td>14.359</td><td>27.051</td><td>15.455</td><td>30.950</td><td>0.532 </td><td>1.002 </td><td>0.572 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 68.9 </td><td>116.18</td><td>5.809 </td><td>10.590</td><td>19.956</td><td>11.477</td><td>22.910</td><td>0.530 </td><td>0.998 </td><td>0.574 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 31.0 </td><td> 60.06</td><td>7.508 </td><td> 4.483</td><td> 8.422</td><td> 4.432</td><td> 9.249</td><td>0.560 </td><td>1.053 </td><td>0.554 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 55.4 </td><td>108.15</td><td>6.759 </td><td> 9.822</td><td>15.862</td><td>10.500</td><td>17.870</td><td>0.614 </td><td>0.991 </td><td>0.656 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 46.0 </td><td>112.24</td><td>4.677 </td><td>12.214</td><td>23.069</td><td>14.091</td><td>27.322</td><td>0.509 </td><td>0.961 </td><td>0.587 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>101.0 </td><td>122.13</td><td>8.142 </td><td>10.010</td><td>15.305</td><td>10.193</td><td>16.664</td><td>0.667 </td><td>1.020 </td><td>0.680 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 62.8 </td><td>108.15</td><td>6.759 </td><td> 9.822</td><td>15.862</td><td>10.500</td><td>17.870</td><td>0.614 </td><td>0.991 </td><td>0.656 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 83.0 </td><td>124.15</td><td>7.303 </td><td>10.537</td><td>17.189</td><td>10.955</td><td>19.080</td><td>0.620 </td><td>1.011 </td><td>0.644 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>103.0 </td><td>138.18</td><td>6.909 </td><td>12.064</td><td>20.073</td><td>12.716</td><td>22.495</td><td>0.603 </td><td>1.004 </td><td>0.636 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 19.6 </td><td> 74.14</td><td>4.943 </td><td> 7.349</td><td>14.745</td><td> 8.262</td><td>17.285</td><td>0.490 </td><td>0.983 </td><td>0.551 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>160.0 </td><td>192.28</td><td>6.409 </td><td>17.644</td><td>29.723</td><td>19.000</td><td>33.740</td><td>0.588 </td><td>0.991 </td><td>0.633 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>270.0 </td><td>196.32</td><td>5.774 </td><td>18.698</td><td>33.491</td><td>20.523</td><td>38.571</td><td>0.550 </td><td>0.985 </td><td>0.604 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>103.0 </td><td>115.15</td><td>6.774 </td><td> 9.558</td><td>17.291</td><td> 9.960</td><td>19.578</td><td>0.562 </td><td>1.017 </td><td>0.586 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>153.0 </td><td>214.39</td><td>5.229 </td><td>21.278</td><td>40.141</td><td>23.807</td><td>46.816</td><td>0.519 </td><td>0.979 </td><td>0.581 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>   </td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td> 89.0 </td><td>170.33</td><td> 5.010</td><td>17.510</td><td>33.047</td><td>19.830</td><td>38.777</td><td>0.515 </td><td>0.972 </td><td>0.583 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 17.5 </td><td>122.28</td><td> 7.643</td><td> 9.008</td><td>15.571</td><td>11.102</td><td>17.916</td><td>0.563 </td><td>0.973 </td><td>0.694 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 59.1 </td><td>102.15</td><td> 6.009</td><td> 9.064</td><td>17.073</td><td> 9.716</td><td>19.495</td><td>0.533 </td><td>1.004 </td><td>0.572 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>156.0 </td><td>178.25</td><td> 6.602</td><td>16.117</td><td>26.840</td><td>17.239</td><td>30.325</td><td>0.597 </td><td>0.994 </td><td>0.638 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>173.0 </td><td>214.31</td><td> 7.654</td><td>17.019</td><td>28.244</td><td>18.341</td><td>31.455</td><td>0.608 </td><td>1.009 </td><td>0.655 </td><td>...   </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 49.5 </td><td> 88.12</td><td> 6.294</td><td> 7.537</td><td>14.189</td><td> 7.955</td><td>16.080</td><td>0.538 </td><td>1.014 </td><td>0.568 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 76.4 </td><td>112.19</td><td> 5.610</td><td>10.876</td><td>19.629</td><td>12.023</td><td>22.701</td><td>0.544 </td><td>0.981 </td><td>0.601 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>143.0 </td><td>170.28</td><td> 5.676</td><td>16.171</td><td>29.607</td><td>17.762</td><td>34.156</td><td>0.539 </td><td>0.987 </td><td>0.592 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 32.9 </td><td> 86.15</td><td> 5.384</td><td> 8.349</td><td>15.745</td><td> 9.262</td><td>18.285</td><td>0.522 </td><td>0.984 </td><td>0.579 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 89.3 </td><td>144.24</td><td> 5.548</td><td>13.644</td><td>25.723</td><td>15.000</td><td>29.740</td><td>0.525 </td><td>0.989 </td><td>0.577 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>128.0 </td><td>166.25</td><td> 6.394</td><td>14.918</td><td>25.833</td><td>16.034</td><td>29.697</td><td>0.574 </td><td>0.994 </td><td>0.617 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>156.0 </td><td>178.25</td><td> 6.602</td><td>16.117</td><td>26.840</td><td>17.239</td><td>30.325</td><td>0.597 </td><td>0.994 </td><td>0.638 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>117.0 </td><td>150.15</td><td> 7.507</td><td>11.208</td><td>21.055</td><td>11.079</td><td>23.123</td><td>0.560 </td><td>1.053 </td><td>0.554 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>101.0 </td><td>120.16</td><td> 7.068</td><td>10.822</td><td>16.862</td><td>11.500</td><td>18.870</td><td>0.637 </td><td>0.992 </td><td>0.676 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 12.4 </td><td>126.29</td><td>11.481</td><td> 7.142</td><td>10.880</td><td> 9.227</td><td>12.006</td><td>0.649 </td><td>0.989 </td><td>0.839 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>150.0 </td><td>154.28</td><td> 5.320</td><td>15.456</td><td>28.280</td><td>17.307</td><td>32.946</td><td>0.533 </td><td>0.975 </td><td>0.597 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 10.3 </td><td> 44.06</td><td> 6.294</td><td> 3.768</td><td> 7.095</td><td> 3.977</td><td> 8.040</td><td>0.538 </td><td>1.014 </td><td>0.568 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 11.1 </td><td> 90.21</td><td> 6.014</td><td> 7.821</td><td>14.494</td><td> 9.455</td><td>16.996</td><td>0.521 </td><td>0.966 </td><td>0.630 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td>177.0 </td><td>162.20</td><td> 7.373</td><td>14.064</td><td>22.073</td><td>14.716</td><td>24.495</td><td>0.639 </td><td>1.003 </td><td>0.669 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 26.5 </td><td> 80.10</td><td> 8.010</td><td> 6.570</td><td>10.087</td><td> 6.773</td><td>11.412</td><td>0.657 </td><td>1.009 </td><td>0.677 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 43.2 </td><td> 82.11</td><td> 6.843</td><td> 7.295</td><td>11.978</td><td> 7.739</td><td>13.455</td><td>0.608 </td><td>0.998 </td><td>0.645 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>108.0 </td><td>158.27</td><td> 5.458</td><td>15.171</td><td>28.607</td><td>16.762</td><td>33.156</td><td>0.523 </td><td>0.986 </td><td>0.578 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 35.4 </td><td>116.23</td><td> 4.843</td><td>11.929</td><td>23.396</td><td>13.546</td><td>27.531</td><td>0.497 </td><td>0.975 </td><td>0.564 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 95.1 </td><td>142.19</td><td> 9.479</td><td>10.197</td><td>15.382</td><td>10.841</td><td>16.584</td><td>0.680 </td><td>1.025 </td><td>0.723 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 82.7 </td><td>136.21</td><td> 6.191</td><td>12.876</td><td>21.629</td><td>14.023</td><td>24.701</td><td>0.585 </td><td>0.983 </td><td>0.637 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td> 85.0 </td><td>140.22</td><td> 8.248</td><td>11.009</td><td>16.938</td><td>12.148</td><td>18.790</td><td>0.648 </td><td>0.996 </td><td>0.715 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 76.6 </td><td>116.18</td><td> 5.809</td><td>10.590</td><td>19.956</td><td>11.477</td><td>22.910</td><td>0.530 </td><td>0.998 </td><td>0.574 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 83.0 </td><td>124.15</td><td> 7.303</td><td>10.537</td><td>17.189</td><td>10.955</td><td>19.080</td><td>0.620 </td><td>1.011 </td><td>0.644 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "\t<tr><td>101.0 </td><td>122.13</td><td> 8.142</td><td>10.010</td><td>15.305</td><td>10.193</td><td>16.664</td><td>0.667 </td><td>1.020 </td><td>0.680 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td></tr>\n",
       "\t<tr><td> 17.6 </td><td> 74.14</td><td> 4.943</td><td> 7.349</td><td>14.745</td><td> 8.262</td><td>17.285</td><td>0.490 </td><td>0.983 </td><td>0.551 </td><td>...   </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>0     </td><td>1     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " complexity.from.pubmed & MW & AMW & Sv & Se & Sp & Si & Mv & Me & Mp & ... & Depressant.50 & Hypertens.80 & Hypertens.50 & Hypnotic.80 & Hypnotic.50 & Neoplastic.80 & Neoplastic.50 & Infective.80 & Infective.50 & Intensity\\\\\n",
       "\\hline\n",
       "\t 302.0  & 208.33 & 5.952  & 19.698 & 34.491 & 21.523 & 39.571 & 0.563  & 0.985  & 0.615  & ...    & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 1     \\\\\n",
       "\t  72.6  & 122.18 & 6.431  & 11.349 & 18.745 & 12.261 & 21.285 & 0.597  & 0.987  & 0.645  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 259.0  & 242.29 & 7.572  & 20.832 & 32.167 & 21.693 & 35.535 & 0.651  & 1.005  & 0.678  & ...    & 0      & 1      & 0      & 1      & 1      & 1      & 0      & 1      & 1      & 0     \\\\\n",
       "\t  56.6  &  88.12 & 6.294  &  7.537 & 14.189 &  7.955 & 16.080 & 0.538  & 1.014  & 0.568  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  84.7  & 136.21 & 6.191  & 12.876 & 21.629 & 14.023 & 24.701 & 0.585  & 0.983  & 0.637  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 160.0  & 192.28 & 6.409  & 17.644 & 29.723 & 19.000 & 33.740 & 0.588  & 0.991  & 0.633  & ...    & 0      & 0      & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 0     \\\\\n",
       "\t 116.0  & 170.22 & 7.401  & 15.349 & 22.745 & 16.261 & 25.285 & 0.667  & 0.989  & 0.707  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 1     \\\\\n",
       "\t  25.0  & 114.26 & 4.395  & 12.741 & 24.952 & 14.853 & 29.737 & 0.490  & 0.960  & 0.571  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 355.0  & 268.30 & 7.666  & 21.304 & 36.025 & 21.614 & 39.950 & 0.609  & 1.029  & 0.618  & ...    & 0      & 1      & 0      & 1      & 1      & 1      & 1      & 1      & 1      & 1     \\\\\n",
       "\t  68.4  & 152.26 & 9.516  &  9.911 & 16.342 & 11.250 & 17.920 & 0.619  & 1.021  & 0.703  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 155.0  & 148.17 & 7.798  & 12.537 & 19.189 & 12.955 & 21.080 & 0.660  & 1.010  & 0.682  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  25.1  &  88.17 & 4.898  &  8.876 & 17.629 & 10.023 & 20.701 & 0.493  & 0.979  & 0.557  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  35.2  & 102.20 & 4.867  & 10.402 & 20.513 & 11.784 & 24.116 & 0.495  & 0.977  & 0.561  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 101.0  & 134.19 & 6.710  & 12.349 & 19.745 & 13.261 & 22.285 & 0.617  & 0.987  & 0.663  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 114.0  & 146.16 & 7.308  & 11.493 & 20.727 & 11.625 & 22.914 & 0.575  & 1.036  & 0.581  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  52.5  & 130.26 & 4.824  & 13.456 & 26.280 & 15.307 & 30.946 & 0.498  & 0.973  & 0.567  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 112.0  & 160.24 & 5.935  & 14.359 & 27.051 & 15.455 & 30.950 & 0.532  & 1.002  & 0.572  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  68.9  & 116.18 & 5.809  & 10.590 & 19.956 & 11.477 & 22.910 & 0.530  & 0.998  & 0.574  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  31.0  &  60.06 & 7.508  &  4.483 &  8.422 &  4.432 &  9.249 & 0.560  & 1.053  & 0.554  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  55.4  & 108.15 & 6.759  &  9.822 & 15.862 & 10.500 & 17.870 & 0.614  & 0.991  & 0.656  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  46.0  & 112.24 & 4.677  & 12.214 & 23.069 & 14.091 & 27.322 & 0.509  & 0.961  & 0.587  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 101.0  & 122.13 & 8.142  & 10.010 & 15.305 & 10.193 & 16.664 & 0.667  & 1.020  & 0.680  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  62.8  & 108.15 & 6.759  &  9.822 & 15.862 & 10.500 & 17.870 & 0.614  & 0.991  & 0.656  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  83.0  & 124.15 & 7.303  & 10.537 & 17.189 & 10.955 & 19.080 & 0.620  & 1.011  & 0.644  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 103.0  & 138.18 & 6.909  & 12.064 & 20.073 & 12.716 & 22.495 & 0.603  & 1.004  & 0.636  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  19.6  &  74.14 & 4.943  &  7.349 & 14.745 &  8.262 & 17.285 & 0.490  & 0.983  & 0.551  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 160.0  & 192.28 & 6.409  & 17.644 & 29.723 & 19.000 & 33.740 & 0.588  & 0.991  & 0.633  & ...    & 0      & 0      & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 1     \\\\\n",
       "\t 270.0  & 196.32 & 5.774  & 18.698 & 33.491 & 20.523 & 38.571 & 0.550  & 0.985  & 0.604  & ...    & 0      & 0      & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 0     \\\\\n",
       "\t 103.0  & 115.15 & 6.774  &  9.558 & 17.291 &  9.960 & 19.578 & 0.562  & 1.017  & 0.586  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 153.0  & 214.39 & 5.229  & 21.278 & 40.141 & 23.807 & 46.816 & 0.519  & 0.979  & 0.581  & ...    & 0      & 0      & 0      & 0      & 0      & 1      & 0      & 1      & 0      & 1     \\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ... & ... & ... & ... &     & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t  89.0  & 170.33 &  5.010 & 17.510 & 33.047 & 19.830 & 38.777 & 0.515  & 0.972  & 0.583  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  17.5  & 122.28 &  7.643 &  9.008 & 15.571 & 11.102 & 17.916 & 0.563  & 0.973  & 0.694  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  59.1  & 102.15 &  6.009 &  9.064 & 17.073 &  9.716 & 19.495 & 0.533  & 1.004  & 0.572  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 156.0  & 178.25 &  6.602 & 16.117 & 26.840 & 17.239 & 30.325 & 0.597  & 0.994  & 0.638  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 1     \\\\\n",
       "\t 173.0  & 214.31 &  7.654 & 17.019 & 28.244 & 18.341 & 31.455 & 0.608  & 1.009  & 0.655  & ...    & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 1      & 0      & 0     \\\\\n",
       "\t  49.5  &  88.12 &  6.294 &  7.537 & 14.189 &  7.955 & 16.080 & 0.538  & 1.014  & 0.568  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  76.4  & 112.19 &  5.610 & 10.876 & 19.629 & 12.023 & 22.701 & 0.544  & 0.981  & 0.601  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 143.0  & 170.28 &  5.676 & 16.171 & 29.607 & 17.762 & 34.156 & 0.539  & 0.987  & 0.592  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 0     \\\\\n",
       "\t  32.9  &  86.15 &  5.384 &  8.349 & 15.745 &  9.262 & 18.285 & 0.522  & 0.984  & 0.579  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  89.3  & 144.24 &  5.548 & 13.644 & 25.723 & 15.000 & 29.740 & 0.525  & 0.989  & 0.577  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 128.0  & 166.25 &  6.394 & 14.918 & 25.833 & 16.034 & 29.697 & 0.574  & 0.994  & 0.617  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 0     \\\\\n",
       "\t 156.0  & 178.25 &  6.602 & 16.117 & 26.840 & 17.239 & 30.325 & 0.597  & 0.994  & 0.638  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 0     \\\\\n",
       "\t 117.0  & 150.15 &  7.507 & 11.208 & 21.055 & 11.079 & 23.123 & 0.560  & 1.053  & 0.554  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 101.0  & 120.16 &  7.068 & 10.822 & 16.862 & 11.500 & 18.870 & 0.637  & 0.992  & 0.676  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  12.4  & 126.29 & 11.481 &  7.142 & 10.880 &  9.227 & 12.006 & 0.649  & 0.989  & 0.839  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 150.0  & 154.28 &  5.320 & 15.456 & 28.280 & 17.307 & 32.946 & 0.533  & 0.975  & 0.597  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1      & 0      & 0     \\\\\n",
       "\t  10.3  &  44.06 &  6.294 &  3.768 &  7.095 &  3.977 &  8.040 & 0.538  & 1.014  & 0.568  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  11.1  &  90.21 &  6.014 &  7.821 & 14.494 &  9.455 & 16.996 & 0.521  & 0.966  & 0.630  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t 177.0  & 162.20 &  7.373 & 14.064 & 22.073 & 14.716 & 24.495 & 0.639  & 1.003  & 0.669  & ...    & 0      & 0      & 0      & 1      & 0      & 0      & 0      & 1      & 0      & 0     \\\\\n",
       "\t  26.5  &  80.10 &  8.010 &  6.570 & 10.087 &  6.773 & 11.412 & 0.657  & 1.009  & 0.677  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  43.2  &  82.11 &  6.843 &  7.295 & 11.978 &  7.739 & 13.455 & 0.608  & 0.998  & 0.645  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 108.0  & 158.27 &  5.458 & 15.171 & 28.607 & 16.762 & 33.156 & 0.523  & 0.986  & 0.578  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1      & 0      & 1     \\\\\n",
       "\t  35.4  & 116.23 &  4.843 & 11.929 & 23.396 & 13.546 & 27.531 & 0.497  & 0.975  & 0.564  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  95.1  & 142.19 &  9.479 & 10.197 & 15.382 & 10.841 & 16.584 & 0.680  & 1.025  & 0.723  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  82.7  & 136.21 &  6.191 & 12.876 & 21.629 & 14.023 & 24.701 & 0.585  & 0.983  & 0.637  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t  85.0  & 140.22 &  8.248 & 11.009 & 16.938 & 12.148 & 18.790 & 0.648  & 0.996  & 0.715  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  76.6  & 116.18 &  5.809 & 10.590 & 19.956 & 11.477 & 22.910 & 0.530  & 0.998  & 0.574  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  83.0  & 124.15 &  7.303 & 10.537 & 17.189 & 10.955 & 19.080 & 0.620  & 1.011  & 0.644  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\t 101.0  & 122.13 &  8.142 & 10.010 & 15.305 & 10.193 & 16.664 & 0.667  & 1.020  & 0.680  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0     \\\\\n",
       "\t  17.6  &  74.14 &  4.943 &  7.349 & 14.745 &  8.262 & 17.285 & 0.490  & 0.983  & 0.551  & ...    & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 1     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| complexity.from.pubmed | MW | AMW | Sv | Se | Sp | Si | Mv | Me | Mp | ... | Depressant.50 | Hypertens.80 | Hypertens.50 | Hypnotic.80 | Hypnotic.50 | Neoplastic.80 | Neoplastic.50 | Infective.80 | Infective.50 | Intensity |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 302.0  | 208.33 | 5.952  | 19.698 | 34.491 | 21.523 | 39.571 | 0.563  | 0.985  | 0.615  | ...    | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 1      |\n",
       "|  72.6  | 122.18 | 6.431  | 11.349 | 18.745 | 12.261 | 21.285 | 0.597  | 0.987  | 0.645  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 259.0  | 242.29 | 7.572  | 20.832 | 32.167 | 21.693 | 35.535 | 0.651  | 1.005  | 0.678  | ...    | 0      | 1      | 0      | 1      | 1      | 1      | 0      | 1      | 1      | 0      |\n",
       "|  56.6  |  88.12 | 6.294  |  7.537 | 14.189 |  7.955 | 16.080 | 0.538  | 1.014  | 0.568  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  84.7  | 136.21 | 6.191  | 12.876 | 21.629 | 14.023 | 24.701 | 0.585  | 0.983  | 0.637  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 160.0  | 192.28 | 6.409  | 17.644 | 29.723 | 19.000 | 33.740 | 0.588  | 0.991  | 0.633  | ...    | 0      | 0      | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 0      |\n",
       "| 116.0  | 170.22 | 7.401  | 15.349 | 22.745 | 16.261 | 25.285 | 0.667  | 0.989  | 0.707  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 1      |\n",
       "|  25.0  | 114.26 | 4.395  | 12.741 | 24.952 | 14.853 | 29.737 | 0.490  | 0.960  | 0.571  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 355.0  | 268.30 | 7.666  | 21.304 | 36.025 | 21.614 | 39.950 | 0.609  | 1.029  | 0.618  | ...    | 0      | 1      | 0      | 1      | 1      | 1      | 1      | 1      | 1      | 1      |\n",
       "|  68.4  | 152.26 | 9.516  |  9.911 | 16.342 | 11.250 | 17.920 | 0.619  | 1.021  | 0.703  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 155.0  | 148.17 | 7.798  | 12.537 | 19.189 | 12.955 | 21.080 | 0.660  | 1.010  | 0.682  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  25.1  |  88.17 | 4.898  |  8.876 | 17.629 | 10.023 | 20.701 | 0.493  | 0.979  | 0.557  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  35.2  | 102.20 | 4.867  | 10.402 | 20.513 | 11.784 | 24.116 | 0.495  | 0.977  | 0.561  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 101.0  | 134.19 | 6.710  | 12.349 | 19.745 | 13.261 | 22.285 | 0.617  | 0.987  | 0.663  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 114.0  | 146.16 | 7.308  | 11.493 | 20.727 | 11.625 | 22.914 | 0.575  | 1.036  | 0.581  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  52.5  | 130.26 | 4.824  | 13.456 | 26.280 | 15.307 | 30.946 | 0.498  | 0.973  | 0.567  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 112.0  | 160.24 | 5.935  | 14.359 | 27.051 | 15.455 | 30.950 | 0.532  | 1.002  | 0.572  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  68.9  | 116.18 | 5.809  | 10.590 | 19.956 | 11.477 | 22.910 | 0.530  | 0.998  | 0.574  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  31.0  |  60.06 | 7.508  |  4.483 |  8.422 |  4.432 |  9.249 | 0.560  | 1.053  | 0.554  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  55.4  | 108.15 | 6.759  |  9.822 | 15.862 | 10.500 | 17.870 | 0.614  | 0.991  | 0.656  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  46.0  | 112.24 | 4.677  | 12.214 | 23.069 | 14.091 | 27.322 | 0.509  | 0.961  | 0.587  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 101.0  | 122.13 | 8.142  | 10.010 | 15.305 | 10.193 | 16.664 | 0.667  | 1.020  | 0.680  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  62.8  | 108.15 | 6.759  |  9.822 | 15.862 | 10.500 | 17.870 | 0.614  | 0.991  | 0.656  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  83.0  | 124.15 | 7.303  | 10.537 | 17.189 | 10.955 | 19.080 | 0.620  | 1.011  | 0.644  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 103.0  | 138.18 | 6.909  | 12.064 | 20.073 | 12.716 | 22.495 | 0.603  | 1.004  | 0.636  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  19.6  |  74.14 | 4.943  |  7.349 | 14.745 |  8.262 | 17.285 | 0.490  | 0.983  | 0.551  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 160.0  | 192.28 | 6.409  | 17.644 | 29.723 | 19.000 | 33.740 | 0.588  | 0.991  | 0.633  | ...    | 0      | 0      | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 1      |\n",
       "| 270.0  | 196.32 | 5.774  | 18.698 | 33.491 | 20.523 | 38.571 | 0.550  | 0.985  | 0.604  | ...    | 0      | 0      | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 0      |\n",
       "| 103.0  | 115.15 | 6.774  |  9.558 | 17.291 |  9.960 | 19.578 | 0.562  | 1.017  | 0.586  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 153.0  | 214.39 | 5.229  | 21.278 | 40.141 | 23.807 | 46.816 | 0.519  | 0.979  | 0.581  | ...    | 0      | 0      | 0      | 0      | 0      | 1      | 0      | 1      | 0      | 1      |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |     | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "|  89.0  | 170.33 |  5.010 | 17.510 | 33.047 | 19.830 | 38.777 | 0.515  | 0.972  | 0.583  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  17.5  | 122.28 |  7.643 |  9.008 | 15.571 | 11.102 | 17.916 | 0.563  | 0.973  | 0.694  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  59.1  | 102.15 |  6.009 |  9.064 | 17.073 |  9.716 | 19.495 | 0.533  | 1.004  | 0.572  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 156.0  | 178.25 |  6.602 | 16.117 | 26.840 | 17.239 | 30.325 | 0.597  | 0.994  | 0.638  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 1      |\n",
       "| 173.0  | 214.31 |  7.654 | 17.019 | 28.244 | 18.341 | 31.455 | 0.608  | 1.009  | 0.655  | ...    | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 1      | 0      | 0      |\n",
       "|  49.5  |  88.12 |  6.294 |  7.537 | 14.189 |  7.955 | 16.080 | 0.538  | 1.014  | 0.568  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  76.4  | 112.19 |  5.610 | 10.876 | 19.629 | 12.023 | 22.701 | 0.544  | 0.981  | 0.601  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 143.0  | 170.28 |  5.676 | 16.171 | 29.607 | 17.762 | 34.156 | 0.539  | 0.987  | 0.592  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 0      |\n",
       "|  32.9  |  86.15 |  5.384 |  8.349 | 15.745 |  9.262 | 18.285 | 0.522  | 0.984  | 0.579  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  89.3  | 144.24 |  5.548 | 13.644 | 25.723 | 15.000 | 29.740 | 0.525  | 0.989  | 0.577  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 128.0  | 166.25 |  6.394 | 14.918 | 25.833 | 16.034 | 29.697 | 0.574  | 0.994  | 0.617  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 0      |\n",
       "| 156.0  | 178.25 |  6.602 | 16.117 | 26.840 | 17.239 | 30.325 | 0.597  | 0.994  | 0.638  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 0      |\n",
       "| 117.0  | 150.15 |  7.507 | 11.208 | 21.055 | 11.079 | 23.123 | 0.560  | 1.053  | 0.554  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 101.0  | 120.16 |  7.068 | 10.822 | 16.862 | 11.500 | 18.870 | 0.637  | 0.992  | 0.676  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  12.4  | 126.29 | 11.481 |  7.142 | 10.880 |  9.227 | 12.006 | 0.649  | 0.989  | 0.839  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 150.0  | 154.28 |  5.320 | 15.456 | 28.280 | 17.307 | 32.946 | 0.533  | 0.975  | 0.597  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      | 0      | 0      |\n",
       "|  10.3  |  44.06 |  6.294 |  3.768 |  7.095 |  3.977 |  8.040 | 0.538  | 1.014  | 0.568  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  11.1  |  90.21 |  6.014 |  7.821 | 14.494 |  9.455 | 16.996 | 0.521  | 0.966  | 0.630  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "| 177.0  | 162.20 |  7.373 | 14.064 | 22.073 | 14.716 | 24.495 | 0.639  | 1.003  | 0.669  | ...    | 0      | 0      | 0      | 1      | 0      | 0      | 0      | 1      | 0      | 0      |\n",
       "|  26.5  |  80.10 |  8.010 |  6.570 | 10.087 |  6.773 | 11.412 | 0.657  | 1.009  | 0.677  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  43.2  |  82.11 |  6.843 |  7.295 | 11.978 |  7.739 | 13.455 | 0.608  | 0.998  | 0.645  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 108.0  | 158.27 |  5.458 | 15.171 | 28.607 | 16.762 | 33.156 | 0.523  | 0.986  | 0.578  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      | 0      | 1      |\n",
       "|  35.4  | 116.23 |  4.843 | 11.929 | 23.396 | 13.546 | 27.531 | 0.497  | 0.975  | 0.564  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  95.1  | 142.19 |  9.479 | 10.197 | 15.382 | 10.841 | 16.584 | 0.680  | 1.025  | 0.723  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  82.7  | 136.21 |  6.191 | 12.876 | 21.629 | 14.023 | 24.701 | 0.585  | 0.983  | 0.637  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "|  85.0  | 140.22 |  8.248 | 11.009 | 16.938 | 12.148 | 18.790 | 0.648  | 0.996  | 0.715  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  76.6  | 116.18 |  5.809 | 10.590 | 19.956 | 11.477 | 22.910 | 0.530  | 0.998  | 0.574  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  83.0  | 124.15 |  7.303 | 10.537 | 17.189 | 10.955 | 19.080 | 0.620  | 1.011  | 0.644  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "| 101.0  | 122.13 |  8.142 | 10.010 | 15.305 | 10.193 | 16.664 | 0.667  | 1.020  | 0.680  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      |\n",
       "|  17.6  |  74.14 |  4.943 |  7.349 | 14.745 |  8.262 | 17.285 | 0.490  | 0.983  | 0.551  | ...    | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 1      |\n",
       "\n"
      ],
      "text/plain": [
       "    complexity.from.pubmed MW     AMW    Sv     Se     Sp     Si     Mv   \n",
       "1   302.0                  208.33 5.952  19.698 34.491 21.523 39.571 0.563\n",
       "2    72.6                  122.18 6.431  11.349 18.745 12.261 21.285 0.597\n",
       "3   259.0                  242.29 7.572  20.832 32.167 21.693 35.535 0.651\n",
       "4    56.6                   88.12 6.294   7.537 14.189  7.955 16.080 0.538\n",
       "5    84.7                  136.21 6.191  12.876 21.629 14.023 24.701 0.585\n",
       "6   160.0                  192.28 6.409  17.644 29.723 19.000 33.740 0.588\n",
       "7   116.0                  170.22 7.401  15.349 22.745 16.261 25.285 0.667\n",
       "8    25.0                  114.26 4.395  12.741 24.952 14.853 29.737 0.490\n",
       "9   355.0                  268.30 7.666  21.304 36.025 21.614 39.950 0.609\n",
       "10   68.4                  152.26 9.516   9.911 16.342 11.250 17.920 0.619\n",
       "11  155.0                  148.17 7.798  12.537 19.189 12.955 21.080 0.660\n",
       "12   25.1                   88.17 4.898   8.876 17.629 10.023 20.701 0.493\n",
       "13   35.2                  102.20 4.867  10.402 20.513 11.784 24.116 0.495\n",
       "14  101.0                  134.19 6.710  12.349 19.745 13.261 22.285 0.617\n",
       "15  114.0                  146.16 7.308  11.493 20.727 11.625 22.914 0.575\n",
       "16   52.5                  130.26 4.824  13.456 26.280 15.307 30.946 0.498\n",
       "17  112.0                  160.24 5.935  14.359 27.051 15.455 30.950 0.532\n",
       "18   68.9                  116.18 5.809  10.590 19.956 11.477 22.910 0.530\n",
       "19   31.0                   60.06 7.508   4.483  8.422  4.432  9.249 0.560\n",
       "20   55.4                  108.15 6.759   9.822 15.862 10.500 17.870 0.614\n",
       "21   46.0                  112.24 4.677  12.214 23.069 14.091 27.322 0.509\n",
       "22  101.0                  122.13 8.142  10.010 15.305 10.193 16.664 0.667\n",
       "23   62.8                  108.15 6.759   9.822 15.862 10.500 17.870 0.614\n",
       "24   83.0                  124.15 7.303  10.537 17.189 10.955 19.080 0.620\n",
       "25  103.0                  138.18 6.909  12.064 20.073 12.716 22.495 0.603\n",
       "26   19.6                   74.14 4.943   7.349 14.745  8.262 17.285 0.490\n",
       "27  160.0                  192.28 6.409  17.644 29.723 19.000 33.740 0.588\n",
       "28  270.0                  196.32 5.774  18.698 33.491 20.523 38.571 0.550\n",
       "29  103.0                  115.15 6.774   9.558 17.291  9.960 19.578 0.562\n",
       "30  153.0                  214.39 5.229  21.278 40.141 23.807 46.816 0.519\n",
       "... ...                    ...    ...    ...    ...    ...    ...    ...  \n",
       "679  89.0                  170.33  5.010 17.510 33.047 19.830 38.777 0.515\n",
       "680  17.5                  122.28  7.643  9.008 15.571 11.102 17.916 0.563\n",
       "681  59.1                  102.15  6.009  9.064 17.073  9.716 19.495 0.533\n",
       "682 156.0                  178.25  6.602 16.117 26.840 17.239 30.325 0.597\n",
       "683 173.0                  214.31  7.654 17.019 28.244 18.341 31.455 0.608\n",
       "684  49.5                   88.12  6.294  7.537 14.189  7.955 16.080 0.538\n",
       "685  76.4                  112.19  5.610 10.876 19.629 12.023 22.701 0.544\n",
       "686 143.0                  170.28  5.676 16.171 29.607 17.762 34.156 0.539\n",
       "687  32.9                   86.15  5.384  8.349 15.745  9.262 18.285 0.522\n",
       "688  89.3                  144.24  5.548 13.644 25.723 15.000 29.740 0.525\n",
       "689 128.0                  166.25  6.394 14.918 25.833 16.034 29.697 0.574\n",
       "690 156.0                  178.25  6.602 16.117 26.840 17.239 30.325 0.597\n",
       "691 117.0                  150.15  7.507 11.208 21.055 11.079 23.123 0.560\n",
       "692 101.0                  120.16  7.068 10.822 16.862 11.500 18.870 0.637\n",
       "693  12.4                  126.29 11.481  7.142 10.880  9.227 12.006 0.649\n",
       "694 150.0                  154.28  5.320 15.456 28.280 17.307 32.946 0.533\n",
       "695  10.3                   44.06  6.294  3.768  7.095  3.977  8.040 0.538\n",
       "696  11.1                   90.21  6.014  7.821 14.494  9.455 16.996 0.521\n",
       "697 177.0                  162.20  7.373 14.064 22.073 14.716 24.495 0.639\n",
       "698  26.5                   80.10  8.010  6.570 10.087  6.773 11.412 0.657\n",
       "699  43.2                   82.11  6.843  7.295 11.978  7.739 13.455 0.608\n",
       "700 108.0                  158.27  5.458 15.171 28.607 16.762 33.156 0.523\n",
       "701  35.4                  116.23  4.843 11.929 23.396 13.546 27.531 0.497\n",
       "702  95.1                  142.19  9.479 10.197 15.382 10.841 16.584 0.680\n",
       "703  82.7                  136.21  6.191 12.876 21.629 14.023 24.701 0.585\n",
       "704  85.0                  140.22  8.248 11.009 16.938 12.148 18.790 0.648\n",
       "705  76.6                  116.18  5.809 10.590 19.956 11.477 22.910 0.530\n",
       "706  83.0                  124.15  7.303 10.537 17.189 10.955 19.080 0.620\n",
       "707 101.0                  122.13  8.142 10.010 15.305 10.193 16.664 0.667\n",
       "708  17.6                   74.14  4.943  7.349 14.745  8.262 17.285 0.490\n",
       "    Me    Mp    ... Depressant.50 Hypertens.80 Hypertens.50 Hypnotic.80\n",
       "1   0.985 0.615 ... 0             1            0            1          \n",
       "2   0.987 0.645 ... 0             0            0            0          \n",
       "3   1.005 0.678 ... 0             1            0            1          \n",
       "4   1.014 0.568 ... 0             0            0            0          \n",
       "5   0.983 0.637 ... 0             0            0            0          \n",
       "6   0.991 0.633 ... 0             0            0            1          \n",
       "7   0.989 0.707 ... 0             0            0            1          \n",
       "8   0.960 0.571 ... 0             0            0            0          \n",
       "9   1.029 0.618 ... 0             1            0            1          \n",
       "10  1.021 0.703 ... 0             0            0            0          \n",
       "11  1.010 0.682 ... 0             0            0            0          \n",
       "12  0.979 0.557 ... 0             0            0            0          \n",
       "13  0.977 0.561 ... 0             0            0            0          \n",
       "14  0.987 0.663 ... 0             0            0            0          \n",
       "15  1.036 0.581 ... 0             0            0            0          \n",
       "16  0.973 0.567 ... 0             0            0            0          \n",
       "17  1.002 0.572 ... 0             0            0            0          \n",
       "18  0.998 0.574 ... 0             0            0            0          \n",
       "19  1.053 0.554 ... 0             0            0            0          \n",
       "20  0.991 0.656 ... 0             0            0            0          \n",
       "21  0.961 0.587 ... 0             0            0            0          \n",
       "22  1.020 0.680 ... 0             0            0            0          \n",
       "23  0.991 0.656 ... 0             0            0            0          \n",
       "24  1.011 0.644 ... 0             0            0            0          \n",
       "25  1.004 0.636 ... 0             0            0            0          \n",
       "26  0.983 0.551 ... 0             0            0            0          \n",
       "27  0.991 0.633 ... 0             0            0            1          \n",
       "28  0.985 0.604 ... 0             0            0            1          \n",
       "29  1.017 0.586 ... 0             0            0            0          \n",
       "30  0.979 0.581 ... 0             0            0            0          \n",
       "... ...   ...       ...           ...          ...          ...        \n",
       "679 0.972 0.583 ... 0             0            0            0          \n",
       "680 0.973 0.694 ... 0             0            0            0          \n",
       "681 1.004 0.572 ... 0             0            0            0          \n",
       "682 0.994 0.638 ... 0             0            0            1          \n",
       "683 1.009 0.655 ... 0             1            0            1          \n",
       "684 1.014 0.568 ... 0             0            0            0          \n",
       "685 0.981 0.601 ... 0             0            0            0          \n",
       "686 0.987 0.592 ... 0             0            0            1          \n",
       "687 0.984 0.579 ... 0             0            0            0          \n",
       "688 0.989 0.577 ... 0             0            0            0          \n",
       "689 0.994 0.617 ... 0             0            0            1          \n",
       "690 0.994 0.638 ... 0             0            0            1          \n",
       "691 1.053 0.554 ... 0             0            0            0          \n",
       "692 0.992 0.676 ... 0             0            0            0          \n",
       "693 0.989 0.839 ... 0             0            0            0          \n",
       "694 0.975 0.597 ... 0             0            0            0          \n",
       "695 1.014 0.568 ... 0             0            0            0          \n",
       "696 0.966 0.630 ... 0             0            0            0          \n",
       "697 1.003 0.669 ... 0             0            0            1          \n",
       "698 1.009 0.677 ... 0             0            0            0          \n",
       "699 0.998 0.645 ... 0             0            0            0          \n",
       "700 0.986 0.578 ... 0             0            0            0          \n",
       "701 0.975 0.564 ... 0             0            0            0          \n",
       "702 1.025 0.723 ... 0             0            0            0          \n",
       "703 0.983 0.637 ... 0             0            0            0          \n",
       "704 0.996 0.715 ... 0             0            0            0          \n",
       "705 0.998 0.574 ... 0             0            0            0          \n",
       "706 1.011 0.644 ... 0             0            0            0          \n",
       "707 1.020 0.680 ... 0             0            0            0          \n",
       "708 0.983 0.551 ... 0             0            0            0          \n",
       "    Hypnotic.50 Neoplastic.80 Neoplastic.50 Infective.80 Infective.50 Intensity\n",
       "1   0           1             0             1            0            1        \n",
       "2   0           0             0             0            0            0        \n",
       "3   1           1             0             1            1            0        \n",
       "4   0           0             0             0            0            0        \n",
       "5   0           0             0             0            0            1        \n",
       "6   0           1             0             1            0            0        \n",
       "7   0           0             0             1            0            1        \n",
       "8   0           0             0             0            0            1        \n",
       "9   1           1             1             1            1            1        \n",
       "10  0           0             0             0            0            1        \n",
       "11  0           0             0             0            0            1        \n",
       "12  0           0             0             0            0            1        \n",
       "13  0           0             0             0            0            1        \n",
       "14  0           0             0             0            0            0        \n",
       "15  0           0             0             0            0            0        \n",
       "16  0           0             0             0            0            0        \n",
       "17  0           0             0             0            0            1        \n",
       "18  0           0             0             0            0            1        \n",
       "19  0           0             0             0            0            0        \n",
       "20  0           0             0             0            0            1        \n",
       "21  0           0             0             0            0            0        \n",
       "22  0           0             0             0            0            1        \n",
       "23  0           0             0             0            0            0        \n",
       "24  0           0             0             0            0            0        \n",
       "25  0           0             0             0            0            1        \n",
       "26  0           0             0             0            0            1        \n",
       "27  0           1             0             1            0            1        \n",
       "28  0           1             0             1            0            0        \n",
       "29  0           0             0             0            0            0        \n",
       "30  0           1             0             1            0            1        \n",
       "... ...         ...           ...           ...          ...          ...      \n",
       "679 0           0             0             0            0            1        \n",
       "680 0           0             0             0            0            0        \n",
       "681 0           0             0             0            0            1        \n",
       "682 0           0             0             1            0            1        \n",
       "683 0           1             0             1            0            0        \n",
       "684 0           0             0             0            0            0        \n",
       "685 0           0             0             0            0            1        \n",
       "686 0           0             0             1            0            0        \n",
       "687 0           0             0             0            0            0        \n",
       "688 0           0             0             0            0            1        \n",
       "689 0           0             0             1            0            0        \n",
       "690 0           0             0             1            0            0        \n",
       "691 0           0             0             0            0            0        \n",
       "692 0           0             0             0            0            0        \n",
       "693 0           0             0             0            0            0        \n",
       "694 0           0             0             1            0            0        \n",
       "695 0           0             0             0            0            1        \n",
       "696 0           0             0             0            0            0        \n",
       "697 0           0             0             1            0            0        \n",
       "698 0           0             0             0            0            1        \n",
       "699 0           0             0             0            0            1        \n",
       "700 0           0             0             1            0            1        \n",
       "701 0           0             0             0            0            0        \n",
       "702 0           0             0             0            0            0        \n",
       "703 0           0             0             0            0            1        \n",
       "704 0           0             0             0            0            0        \n",
       "705 0           0             0             0            0            0        \n",
       "706 0           0             0             0            0            1        \n",
       "707 0           0             0             0            0            0        \n",
       "708 0           0             0             0            0            1        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(xgboost)\n",
    "library(Matrix)\n",
    "#Boosting Submission\n",
    "set.seed(100)\n",
    "#Preparation of training and test data\n",
    "train <- train.data[, -c(1,2,3)]\n",
    "idx.zero.var <- apply(train, 2, var) == 0\n",
    "\n",
    "train <- train[,!idx.zero.var]\n",
    "test <- test.data[,-c(1,2)]\n",
    "test <- test[,!idx.zero.var]\n",
    "\n",
    "\n",
    "#test$Intensity <- as.factor(test.data$Intensity)\n",
    "train$Intensity <- as.numeric(train.data$Intensity)-1\n",
    "train\n",
    "#test intensity is always at level high, so that the prediction function has a problem (cheat with adding a row that afterwards is substracted)\n",
    "#test <- rbind(test, train[1,])\n",
    "train.x = train\n",
    "\n",
    "train$VALENCE.PLEASANTNESS <- train.data$VALENCE.PLEASANTNESS\n",
    "train.y = train$VALENCE.PLEASANTNESS\n",
    "\n",
    "train.x <- sparse.model.matrix(VALENCE.PLEASANTNESS ~ . -1, data = train)\n",
    "#test.x <- sparse.model.matrix(VALENCE.PLEASANTNESS ~ . -1, data = test)\n",
    "train.y <- train$VALENCE.PLEASANTNESS\n",
    "#validation.y <- data$VALENCE.PLEASANTNESS[-idx.train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test <- test.data[,-c(1,2)]\n",
    "test <- test[,!idx.zero.var]\n",
    "test$Intensity <- as.numeric(test.data$Intensity)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:48.543175 \n",
      "[2]\ttrain-rmse:48.156307 \n",
      "[3]\ttrain-rmse:47.774090 \n",
      "[4]\ttrain-rmse:47.396358 \n",
      "[5]\ttrain-rmse:47.023838 \n",
      "[6]\ttrain-rmse:46.655029 \n",
      "[7]\ttrain-rmse:46.291256 \n",
      "[8]\ttrain-rmse:45.931023 \n",
      "[9]\ttrain-rmse:45.575901 \n",
      "[10]\ttrain-rmse:45.224209 \n",
      "[11]\ttrain-rmse:44.877495 \n",
      "[12]\ttrain-rmse:44.534111 \n",
      "[13]\ttrain-rmse:44.195663 \n",
      "[14]\ttrain-rmse:43.860435 \n",
      "[15]\ttrain-rmse:43.530098 \n",
      "[16]\ttrain-rmse:43.202881 \n",
      "[17]\ttrain-rmse:42.880520 \n",
      "[18]\ttrain-rmse:42.561157 \n",
      "[19]\ttrain-rmse:42.246597 \n",
      "[20]\ttrain-rmse:41.934952 \n",
      "[21]\ttrain-rmse:41.627995 \n",
      "[22]\ttrain-rmse:41.323921 \n",
      "[23]\ttrain-rmse:41.024517 \n",
      "[24]\ttrain-rmse:40.727852 \n",
      "[25]\ttrain-rmse:40.436672 \n",
      "[26]\ttrain-rmse:40.147301 \n",
      "[27]\ttrain-rmse:39.863300 \n",
      "[28]\ttrain-rmse:39.581905 \n",
      "[29]\ttrain-rmse:39.305069 \n",
      "[30]\ttrain-rmse:39.029663 \n",
      "[31]\ttrain-rmse:38.759762 \n",
      "[32]\ttrain-rmse:38.490467 \n",
      "[33]\ttrain-rmse:38.226208 \n",
      "[34]\ttrain-rmse:37.966202 \n",
      "[35]\ttrain-rmse:37.706909 \n",
      "[36]\ttrain-rmse:37.450603 \n",
      "[37]\ttrain-rmse:37.199436 \n",
      "[38]\ttrain-rmse:36.949791 \n",
      "[39]\ttrain-rmse:36.703094 \n",
      "[40]\ttrain-rmse:36.462261 \n",
      "[41]\ttrain-rmse:36.222008 \n",
      "[42]\ttrain-rmse:35.984596 \n",
      "[43]\ttrain-rmse:35.753189 \n",
      "[44]\ttrain-rmse:35.521969 \n",
      "[45]\ttrain-rmse:35.293568 \n",
      "[46]\ttrain-rmse:35.070881 \n",
      "[47]\ttrain-rmse:34.848412 \n",
      "[48]\ttrain-rmse:34.628876 \n",
      "[49]\ttrain-rmse:34.411957 \n",
      "[50]\ttrain-rmse:34.200760 \n",
      "[51]\ttrain-rmse:33.991093 \n",
      "[52]\ttrain-rmse:33.782692 \n",
      "[53]\ttrain-rmse:33.576851 \n",
      "[54]\ttrain-rmse:33.373898 \n",
      "[55]\ttrain-rmse:33.176502 \n",
      "[56]\ttrain-rmse:32.978569 \n",
      "[57]\ttrain-rmse:32.783489 \n",
      "[58]\ttrain-rmse:32.591103 \n",
      "[59]\ttrain-rmse:32.399414 \n",
      "[60]\ttrain-rmse:32.214714 \n",
      "[61]\ttrain-rmse:32.029121 \n",
      "[62]\ttrain-rmse:31.846878 \n",
      "[63]\ttrain-rmse:31.666384 \n",
      "[64]\ttrain-rmse:31.488184 \n",
      "[65]\ttrain-rmse:31.311049 \n",
      "[66]\ttrain-rmse:31.139212 \n",
      "[67]\ttrain-rmse:30.968912 \n",
      "[68]\ttrain-rmse:30.800394 \n",
      "[69]\ttrain-rmse:30.637039 \n",
      "[70]\ttrain-rmse:30.472704 \n",
      "[71]\ttrain-rmse:30.312271 \n",
      "[72]\ttrain-rmse:30.153294 \n",
      "[73]\ttrain-rmse:29.995958 \n",
      "[74]\ttrain-rmse:29.840454 \n",
      "[75]\ttrain-rmse:29.690245 \n",
      "[76]\ttrain-rmse:29.538921 \n",
      "[77]\ttrain-rmse:29.390102 \n",
      "[78]\ttrain-rmse:29.243031 \n",
      "[79]\ttrain-rmse:29.099411 \n",
      "[80]\ttrain-rmse:28.957043 \n",
      "[81]\ttrain-rmse:28.816305 \n",
      "[82]\ttrain-rmse:28.677288 \n",
      "[83]\ttrain-rmse:28.543123 \n",
      "[84]\ttrain-rmse:28.407307 \n",
      "[85]\ttrain-rmse:28.275375 \n",
      "[86]\ttrain-rmse:28.144567 \n",
      "[87]\ttrain-rmse:28.015137 \n",
      "[88]\ttrain-rmse:27.887342 \n",
      "[89]\ttrain-rmse:27.760744 \n",
      "[90]\ttrain-rmse:27.636744 \n",
      "[91]\ttrain-rmse:27.517216 \n",
      "[92]\ttrain-rmse:27.397791 \n",
      "[93]\ttrain-rmse:27.279411 \n",
      "[94]\ttrain-rmse:27.162039 \n",
      "[95]\ttrain-rmse:27.046604 \n",
      "[96]\ttrain-rmse:26.931942 \n",
      "[97]\ttrain-rmse:26.820877 \n",
      "[98]\ttrain-rmse:26.709984 \n",
      "[99]\ttrain-rmse:26.603680 \n",
      "[100]\ttrain-rmse:26.496183 \n",
      "[101]\ttrain-rmse:26.389421 \n",
      "[102]\ttrain-rmse:26.286243 \n",
      "[103]\ttrain-rmse:26.183767 \n",
      "[104]\ttrain-rmse:26.082293 \n",
      "[105]\ttrain-rmse:25.983654 \n",
      "[106]\ttrain-rmse:25.884771 \n",
      "[107]\ttrain-rmse:25.786814 \n",
      "[108]\ttrain-rmse:25.691570 \n",
      "[109]\ttrain-rmse:25.598694 \n",
      "[110]\ttrain-rmse:25.505428 \n",
      "[111]\ttrain-rmse:25.413692 \n",
      "[112]\ttrain-rmse:25.323849 \n",
      "[113]\ttrain-rmse:25.234030 \n",
      "[114]\ttrain-rmse:25.147808 \n",
      "[115]\ttrain-rmse:25.060255 \n",
      "[116]\ttrain-rmse:24.974789 \n",
      "[117]\ttrain-rmse:24.891317 \n",
      "[118]\ttrain-rmse:24.807566 \n",
      "[119]\ttrain-rmse:24.727488 \n",
      "[120]\ttrain-rmse:24.646896 \n",
      "[121]\ttrain-rmse:24.570192 \n",
      "[122]\ttrain-rmse:24.492710 \n",
      "[123]\ttrain-rmse:24.414850 \n",
      "[124]\ttrain-rmse:24.340607 \n",
      "[125]\ttrain-rmse:24.265745 \n",
      "[126]\ttrain-rmse:24.191957 \n",
      "[127]\ttrain-rmse:24.118544 \n",
      "[128]\ttrain-rmse:24.048601 \n",
      "[129]\ttrain-rmse:23.977329 \n",
      "[130]\ttrain-rmse:23.910303 \n",
      "[131]\ttrain-rmse:23.841677 \n",
      "[132]\ttrain-rmse:23.774776 \n",
      "[133]\ttrain-rmse:23.707542 \n",
      "[134]\ttrain-rmse:23.643618 \n",
      "[135]\ttrain-rmse:23.578331 \n",
      "[136]\ttrain-rmse:23.514519 \n",
      "[137]\ttrain-rmse:23.452387 \n",
      "[138]\ttrain-rmse:23.389946 \n",
      "[139]\ttrain-rmse:23.330627 \n",
      "[140]\ttrain-rmse:23.269867 \n",
      "[141]\ttrain-rmse:23.211569 \n",
      "[142]\ttrain-rmse:23.155672 \n",
      "[143]\ttrain-rmse:23.097631 \n",
      "[144]\ttrain-rmse:23.040874 \n",
      "[145]\ttrain-rmse:22.986664 \n",
      "[146]\ttrain-rmse:22.932205 \n",
      "[147]\ttrain-rmse:22.877312 \n",
      "[148]\ttrain-rmse:22.824808 \n",
      "[149]\ttrain-rmse:22.771627 \n",
      "[150]\ttrain-rmse:22.722082 \n",
      "[151]\ttrain-rmse:22.672485 \n",
      "[152]\ttrain-rmse:22.623068 \n",
      "[153]\ttrain-rmse:22.571644 \n",
      "[154]\ttrain-rmse:22.522457 \n",
      "[155]\ttrain-rmse:22.473484 \n",
      "[156]\ttrain-rmse:22.424303 \n",
      "[157]\ttrain-rmse:22.378426 \n",
      "[158]\ttrain-rmse:22.332693 \n",
      "[159]\ttrain-rmse:22.286911 \n",
      "[160]\ttrain-rmse:22.243462 \n",
      "[161]\ttrain-rmse:22.197662 \n",
      "[162]\ttrain-rmse:22.155033 \n",
      "[163]\ttrain-rmse:22.113111 \n",
      "[164]\ttrain-rmse:22.071209 \n",
      "[165]\ttrain-rmse:22.026060 \n",
      "[166]\ttrain-rmse:21.984631 \n",
      "[167]\ttrain-rmse:21.945139 \n",
      "[168]\ttrain-rmse:21.906458 \n",
      "[169]\ttrain-rmse:21.868118 \n",
      "[170]\ttrain-rmse:21.828535 \n",
      "[171]\ttrain-rmse:21.788668 \n",
      "[172]\ttrain-rmse:21.751945 \n",
      "[173]\ttrain-rmse:21.714415 \n",
      "[174]\ttrain-rmse:21.678043 \n",
      "[175]\ttrain-rmse:21.643106 \n",
      "[176]\ttrain-rmse:21.608496 \n",
      "[177]\ttrain-rmse:21.571791 \n",
      "[178]\ttrain-rmse:21.535172 \n",
      "[179]\ttrain-rmse:21.501997 \n",
      "[180]\ttrain-rmse:21.469416 \n",
      "[181]\ttrain-rmse:21.435791 \n",
      "[182]\ttrain-rmse:21.401518 \n",
      "[183]\ttrain-rmse:21.367289 \n",
      "[184]\ttrain-rmse:21.336412 \n",
      "[185]\ttrain-rmse:21.306028 \n",
      "[186]\ttrain-rmse:21.277328 \n",
      "[187]\ttrain-rmse:21.245281 \n",
      "[188]\ttrain-rmse:21.216194 \n",
      "[189]\ttrain-rmse:21.187759 \n",
      "[190]\ttrain-rmse:21.156528 \n",
      "[191]\ttrain-rmse:21.127739 \n",
      "[192]\ttrain-rmse:21.100128 \n",
      "[193]\ttrain-rmse:21.070505 \n",
      "[194]\ttrain-rmse:21.042849 \n",
      "[195]\ttrain-rmse:21.016352 \n",
      "[196]\ttrain-rmse:20.991501 \n",
      "[197]\ttrain-rmse:20.963350 \n",
      "[198]\ttrain-rmse:20.938046 \n",
      "[199]\ttrain-rmse:20.910168 \n",
      "[200]\ttrain-rmse:20.885386 \n",
      "[201]\ttrain-rmse:20.861214 \n",
      "[202]\ttrain-rmse:20.836367 \n",
      "[203]\ttrain-rmse:20.811768 \n",
      "[204]\ttrain-rmse:20.788651 \n",
      "[205]\ttrain-rmse:20.765461 \n",
      "[206]\ttrain-rmse:20.742617 \n",
      "[207]\ttrain-rmse:20.720266 \n",
      "[208]\ttrain-rmse:20.695272 \n",
      "[209]\ttrain-rmse:20.673510 \n",
      "[210]\ttrain-rmse:20.651138 \n",
      "[211]\ttrain-rmse:20.630348 \n",
      "[212]\ttrain-rmse:20.609570 \n",
      "[213]\ttrain-rmse:20.589838 \n",
      "[214]\ttrain-rmse:20.566736 \n",
      "[215]\ttrain-rmse:20.545788 \n",
      "[216]\ttrain-rmse:20.523214 \n",
      "[217]\ttrain-rmse:20.503380 \n",
      "[218]\ttrain-rmse:20.483671 \n",
      "[219]\ttrain-rmse:20.464512 \n",
      "[220]\ttrain-rmse:20.445608 \n",
      "[221]\ttrain-rmse:20.427088 \n",
      "[222]\ttrain-rmse:20.407492 \n",
      "[223]\ttrain-rmse:20.390179 \n",
      "[224]\ttrain-rmse:20.371418 \n",
      "[225]\ttrain-rmse:20.352051 \n",
      "[226]\ttrain-rmse:20.332003 \n",
      "[227]\ttrain-rmse:20.311340 \n",
      "[228]\ttrain-rmse:20.294388 \n",
      "[229]\ttrain-rmse:20.274511 \n",
      "[230]\ttrain-rmse:20.255116 \n",
      "[231]\ttrain-rmse:20.237049 \n",
      "[232]\ttrain-rmse:20.220774 \n",
      "[233]\ttrain-rmse:20.204872 \n",
      "[234]\ttrain-rmse:20.188486 \n",
      "[235]\ttrain-rmse:20.172586 \n",
      "[236]\ttrain-rmse:20.154900 \n",
      "[237]\ttrain-rmse:20.139744 \n",
      "[238]\ttrain-rmse:20.123743 \n",
      "[239]\ttrain-rmse:20.109457 \n",
      "[240]\ttrain-rmse:20.088263 \n",
      "[241]\ttrain-rmse:20.073608 \n",
      "[242]\ttrain-rmse:20.059298 \n",
      "[243]\ttrain-rmse:20.043427 \n",
      "[244]\ttrain-rmse:20.027838 \n",
      "[245]\ttrain-rmse:20.010859 \n",
      "[246]\ttrain-rmse:19.994099 \n",
      "[247]\ttrain-rmse:19.979622 \n",
      "[248]\ttrain-rmse:19.962027 \n",
      "[249]\ttrain-rmse:19.945997 \n",
      "[250]\ttrain-rmse:19.932484 \n",
      "[251]\ttrain-rmse:19.919519 \n",
      "[252]\ttrain-rmse:19.903093 \n",
      "[253]\ttrain-rmse:19.884054 \n",
      "[254]\ttrain-rmse:19.868412 \n",
      "[255]\ttrain-rmse:19.854305 \n",
      "[256]\ttrain-rmse:19.841980 \n",
      "[257]\ttrain-rmse:19.829630 \n",
      "[258]\ttrain-rmse:19.817591 \n",
      "[259]\ttrain-rmse:19.806061 \n",
      "[260]\ttrain-rmse:19.790012 \n",
      "[261]\ttrain-rmse:19.772057 \n",
      "[262]\ttrain-rmse:19.759617 \n",
      "[263]\ttrain-rmse:19.748060 \n",
      "[264]\ttrain-rmse:19.736704 \n",
      "[265]\ttrain-rmse:19.726465 \n",
      "[266]\ttrain-rmse:19.715319 \n",
      "[267]\ttrain-rmse:19.700211 \n",
      "[268]\ttrain-rmse:19.689638 \n",
      "[269]\ttrain-rmse:19.672703 \n",
      "[270]\ttrain-rmse:19.658995 \n",
      "[271]\ttrain-rmse:19.647594 \n",
      "[272]\ttrain-rmse:19.634296 \n",
      "[273]\ttrain-rmse:19.623463 \n",
      "[274]\ttrain-rmse:19.613132 \n",
      "[275]\ttrain-rmse:19.601980 \n",
      "[276]\ttrain-rmse:19.585945 \n",
      "[277]\ttrain-rmse:19.571909 \n",
      "[278]\ttrain-rmse:19.561834 \n",
      "[279]\ttrain-rmse:19.552303 \n",
      "[280]\ttrain-rmse:19.539532 \n",
      "[281]\ttrain-rmse:19.529840 \n",
      "[282]\ttrain-rmse:19.519499 \n",
      "[283]\ttrain-rmse:19.504219 \n",
      "[284]\ttrain-rmse:19.490923 \n",
      "[285]\ttrain-rmse:19.481861 \n",
      "[286]\ttrain-rmse:19.472469 \n",
      "[287]\ttrain-rmse:19.463137 \n",
      "[288]\ttrain-rmse:19.453594 \n",
      "[289]\ttrain-rmse:19.443886 \n",
      "[290]\ttrain-rmse:19.431957 \n",
      "[291]\ttrain-rmse:19.417486 \n",
      "[292]\ttrain-rmse:19.405727 \n",
      "[293]\ttrain-rmse:19.395264 \n",
      "[294]\ttrain-rmse:19.382809 \n",
      "[295]\ttrain-rmse:19.374075 \n",
      "[296]\ttrain-rmse:19.365412 \n",
      "[297]\ttrain-rmse:19.354000 \n",
      "[298]\ttrain-rmse:19.344975 \n",
      "[299]\ttrain-rmse:19.336889 \n",
      "[300]\ttrain-rmse:19.328539 \n",
      "[301]\ttrain-rmse:19.317766 \n",
      "[302]\ttrain-rmse:19.307955 \n",
      "[303]\ttrain-rmse:19.300053 \n",
      "[304]\ttrain-rmse:19.292789 \n",
      "[305]\ttrain-rmse:19.284697 \n",
      "[306]\ttrain-rmse:19.273104 \n",
      "[307]\ttrain-rmse:19.265074 \n",
      "[308]\ttrain-rmse:19.256693 \n",
      "[309]\ttrain-rmse:19.248077 \n",
      "[310]\ttrain-rmse:19.240568 \n",
      "[311]\ttrain-rmse:19.231192 \n",
      "[312]\ttrain-rmse:19.223116 \n",
      "[313]\ttrain-rmse:19.212683 \n",
      "[314]\ttrain-rmse:19.205393 \n",
      "[315]\ttrain-rmse:19.197376 \n",
      "[316]\ttrain-rmse:19.184511 \n",
      "[317]\ttrain-rmse:19.174286 \n",
      "[318]\ttrain-rmse:19.167164 \n",
      "[319]\ttrain-rmse:19.159729 \n",
      "[320]\ttrain-rmse:19.148878 \n",
      "[321]\ttrain-rmse:19.140858 \n",
      "[322]\ttrain-rmse:19.131147 \n",
      "[323]\ttrain-rmse:19.123962 \n",
      "[324]\ttrain-rmse:19.116777 \n",
      "[325]\ttrain-rmse:19.109982 \n",
      "[326]\ttrain-rmse:19.102861 \n",
      "[327]\ttrain-rmse:19.093111 \n",
      "[328]\ttrain-rmse:19.086353 \n",
      "[329]\ttrain-rmse:19.078705 \n",
      "[330]\ttrain-rmse:19.071352 \n",
      "[331]\ttrain-rmse:19.064785 \n",
      "[332]\ttrain-rmse:19.057619 \n",
      "[333]\ttrain-rmse:19.049358 \n",
      "[334]\ttrain-rmse:19.039871 \n",
      "[335]\ttrain-rmse:19.032495 \n",
      "[336]\ttrain-rmse:19.025835 \n",
      "[337]\ttrain-rmse:19.018759 \n",
      "[338]\ttrain-rmse:19.012440 \n",
      "[339]\ttrain-rmse:19.005821 \n",
      "[340]\ttrain-rmse:18.996222 \n",
      "[341]\ttrain-rmse:18.987303 \n",
      "[342]\ttrain-rmse:18.978144 \n",
      "[343]\ttrain-rmse:18.971876 \n",
      "[344]\ttrain-rmse:18.961914 \n",
      "[345]\ttrain-rmse:18.954889 \n",
      "[346]\ttrain-rmse:18.948822 \n",
      "[347]\ttrain-rmse:18.942410 \n",
      "[348]\ttrain-rmse:18.936049 \n",
      "[349]\ttrain-rmse:18.923965 \n",
      "[350]\ttrain-rmse:18.917416 \n",
      "[351]\ttrain-rmse:18.909775 \n",
      "[352]\ttrain-rmse:18.903910 \n",
      "[353]\ttrain-rmse:18.897945 \n",
      "[354]\ttrain-rmse:18.890234 \n",
      "[355]\ttrain-rmse:18.883734 \n",
      "[356]\ttrain-rmse:18.875000 \n",
      "[357]\ttrain-rmse:18.868320 \n",
      "[358]\ttrain-rmse:18.862249 \n",
      "[359]\ttrain-rmse:18.856562 \n",
      "[360]\ttrain-rmse:18.847692 \n",
      "[361]\ttrain-rmse:18.836830 \n",
      "[362]\ttrain-rmse:18.827402 \n",
      "[363]\ttrain-rmse:18.818930 \n",
      "[364]\ttrain-rmse:18.812712 \n",
      "[365]\ttrain-rmse:18.807035 \n",
      "[366]\ttrain-rmse:18.796188 \n",
      "[367]\ttrain-rmse:18.790272 \n",
      "[368]\ttrain-rmse:18.781591 \n",
      "[369]\ttrain-rmse:18.775274 \n",
      "[370]\ttrain-rmse:18.766993 \n",
      "[371]\ttrain-rmse:18.761593 \n",
      "[372]\ttrain-rmse:18.755861 \n",
      "[373]\ttrain-rmse:18.747433 \n",
      "[374]\ttrain-rmse:18.740322 \n",
      "[375]\ttrain-rmse:18.732271 \n",
      "[376]\ttrain-rmse:18.723265 \n",
      "[377]\ttrain-rmse:18.717836 \n",
      "[378]\ttrain-rmse:18.712572 \n",
      "[379]\ttrain-rmse:18.706995 \n",
      "[380]\ttrain-rmse:18.701405 \n",
      "[381]\ttrain-rmse:18.695356 \n",
      "[382]\ttrain-rmse:18.689543 \n",
      "[383]\ttrain-rmse:18.678585 \n",
      "[384]\ttrain-rmse:18.670498 \n",
      "[385]\ttrain-rmse:18.660412 \n",
      "[386]\ttrain-rmse:18.655014 \n",
      "[387]\ttrain-rmse:18.648195 \n",
      "[388]\ttrain-rmse:18.639486 \n",
      "[389]\ttrain-rmse:18.634417 \n",
      "[390]\ttrain-rmse:18.626572 \n",
      "[391]\ttrain-rmse:18.618834 \n",
      "[392]\ttrain-rmse:18.613384 \n",
      "[393]\ttrain-rmse:18.608236 \n",
      "[394]\ttrain-rmse:18.602701 \n",
      "[395]\ttrain-rmse:18.596920 \n",
      "[396]\ttrain-rmse:18.588982 \n",
      "[397]\ttrain-rmse:18.582405 \n",
      "[398]\ttrain-rmse:18.577488 \n",
      "[399]\ttrain-rmse:18.571882 \n",
      "[400]\ttrain-rmse:18.562105 \n",
      "[401]\ttrain-rmse:18.554619 \n",
      "[402]\ttrain-rmse:18.549805 \n",
      "[403]\ttrain-rmse:18.543219 \n",
      "[404]\ttrain-rmse:18.537994 \n",
      "[405]\ttrain-rmse:18.530310 \n",
      "[406]\ttrain-rmse:18.523937 \n",
      "[407]\ttrain-rmse:18.518963 \n",
      "[408]\ttrain-rmse:18.513609 \n",
      "[409]\ttrain-rmse:18.506308 \n",
      "[410]\ttrain-rmse:18.500776 \n",
      "[411]\ttrain-rmse:18.491323 \n",
      "[412]\ttrain-rmse:18.486612 \n",
      "[413]\ttrain-rmse:18.479258 \n",
      "[414]\ttrain-rmse:18.472092 \n",
      "[415]\ttrain-rmse:18.466894 \n",
      "[416]\ttrain-rmse:18.461514 \n",
      "[417]\ttrain-rmse:18.452312 \n",
      "[418]\ttrain-rmse:18.447714 \n",
      "[419]\ttrain-rmse:18.442940 \n",
      "[420]\ttrain-rmse:18.434786 \n",
      "[421]\ttrain-rmse:18.429518 \n",
      "[422]\ttrain-rmse:18.424576 \n",
      "[423]\ttrain-rmse:18.418507 \n",
      "[424]\ttrain-rmse:18.411533 \n",
      "[425]\ttrain-rmse:18.406555 \n",
      "[426]\ttrain-rmse:18.401531 \n",
      "[427]\ttrain-rmse:18.396717 \n",
      "[428]\ttrain-rmse:18.391479 \n",
      "[429]\ttrain-rmse:18.384226 \n",
      "[430]\ttrain-rmse:18.379761 \n",
      "[431]\ttrain-rmse:18.373779 \n",
      "[432]\ttrain-rmse:18.367949 \n",
      "[433]\ttrain-rmse:18.361149 \n",
      "[434]\ttrain-rmse:18.356518 \n",
      "[435]\ttrain-rmse:18.349529 \n",
      "[436]\ttrain-rmse:18.343410 \n",
      "[437]\ttrain-rmse:18.338745 \n",
      "[438]\ttrain-rmse:18.333876 \n",
      "[439]\ttrain-rmse:18.328459 \n",
      "[440]\ttrain-rmse:18.319777 \n",
      "[441]\ttrain-rmse:18.315409 \n",
      "[442]\ttrain-rmse:18.308771 \n",
      "[443]\ttrain-rmse:18.303741 \n",
      "[444]\ttrain-rmse:18.299234 \n",
      "[445]\ttrain-rmse:18.294468 \n",
      "[446]\ttrain-rmse:18.288830 \n",
      "[447]\ttrain-rmse:18.282278 \n",
      "[448]\ttrain-rmse:18.275471 \n",
      "[449]\ttrain-rmse:18.271173 \n",
      "[450]\ttrain-rmse:18.265486 \n",
      "[451]\ttrain-rmse:18.260763 \n",
      "[452]\ttrain-rmse:18.255848 \n",
      "[453]\ttrain-rmse:18.248104 \n",
      "[454]\ttrain-rmse:18.241215 \n",
      "[455]\ttrain-rmse:18.233561 \n",
      "[456]\ttrain-rmse:18.228233 \n",
      "[457]\ttrain-rmse:18.221426 \n",
      "[458]\ttrain-rmse:18.216232 \n",
      "[459]\ttrain-rmse:18.209898 \n",
      "[460]\ttrain-rmse:18.205288 \n",
      "[461]\ttrain-rmse:18.200750 \n",
      "[462]\ttrain-rmse:18.196175 \n",
      "[463]\ttrain-rmse:18.191814 \n",
      "[464]\ttrain-rmse:18.187437 \n",
      "[465]\ttrain-rmse:18.182655 \n",
      "[466]\ttrain-rmse:18.173822 \n",
      "[467]\ttrain-rmse:18.168280 \n",
      "[468]\ttrain-rmse:18.160110 \n",
      "[469]\ttrain-rmse:18.155691 \n",
      "[470]\ttrain-rmse:18.151609 \n",
      "[471]\ttrain-rmse:18.146547 \n",
      "[472]\ttrain-rmse:18.139193 \n",
      "[473]\ttrain-rmse:18.133463 \n",
      "[474]\ttrain-rmse:18.129211 \n",
      "[475]\ttrain-rmse:18.124084 \n",
      "[476]\ttrain-rmse:18.119410 \n",
      "[477]\ttrain-rmse:18.114943 \n",
      "[478]\ttrain-rmse:18.109648 \n",
      "[479]\ttrain-rmse:18.100554 \n",
      "[480]\ttrain-rmse:18.094439 \n",
      "[481]\ttrain-rmse:18.088028 \n",
      "[482]\ttrain-rmse:18.083851 \n",
      "[483]\ttrain-rmse:18.078823 \n",
      "[484]\ttrain-rmse:18.073494 \n",
      "[485]\ttrain-rmse:18.069286 \n",
      "[486]\ttrain-rmse:18.064358 \n",
      "[487]\ttrain-rmse:18.059988 \n",
      "[488]\ttrain-rmse:18.054832 \n",
      "[489]\ttrain-rmse:18.049234 \n",
      "[490]\ttrain-rmse:18.042877 \n",
      "[491]\ttrain-rmse:18.038790 \n",
      "[492]\ttrain-rmse:18.033567 \n",
      "[493]\ttrain-rmse:18.028631 \n",
      "[494]\ttrain-rmse:18.022715 \n",
      "[495]\ttrain-rmse:18.017195 \n",
      "[496]\ttrain-rmse:18.011341 \n",
      "[497]\ttrain-rmse:18.004585 \n",
      "[498]\ttrain-rmse:17.996271 \n",
      "[499]\ttrain-rmse:17.991541 \n",
      "[500]\ttrain-rmse:17.984499 \n"
     ]
    }
   ],
   "source": [
    "boost.heart <- xgboost(train.x, label = train.y,\n",
    "                      objective = \"reg:squarederror\",\n",
    "                      eta = 0.01,\n",
    "                      max_depth = 2,\n",
    "                      nround = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.boost = predict(boost.heart, as.matrix(test))\n",
    "submission <- data.frame(Id = 1:68, VALENCE.PLEASANTNESS = prediction.boost)\n",
    "write.csv(submission, file = \"../Submissions/boosting2.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting 2 - Regularized gradient boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difference between boosting and random forests: in boosting, because the growth of a particular tree takes into account the other trees that have already been grown, smaller trees are typically sufficient (less splits and depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): objet 'x' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): objet 'x' introuvable\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(100)\n",
    "len <- length(x[,1])\n",
    "idx.train <- sample(1:len, 3*len/4)\n",
    "\n",
    "train.x <- x[idx.train,]\n",
    "train.y <- y[idx.train]\n",
    "test.x <- x[-idx.train,]\n",
    "test.y <- y[-idx.train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data =  as.matrix(train.x), label = train.y )\n",
    "dtest = xgb.DMatrix(data =  as.matrix(test.x), label = test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = list(train=dtrain, test=dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:36.493153\ttest-rmse:37.327053 \n",
      "Multiple eval metrics are present. Will use test_rmse for early stopping.\n",
      "Will train until test_rmse hasn't improved in 50 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-rmse:10.149774\ttest-rmse:24.547579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(data = dtrain, \n",
    "                max.depth = 8, \n",
    "                eta = 0.3, \n",
    "                nthread = 2, \n",
    "                nround = 1000, \n",
    "                watchlist = watchlist, \n",
    "                objective = \"reg:squarederror\", \n",
    "                early_stopping_rounds = 50,\n",
    "                print_every_n = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a train-rmse of 10.15 and a test-rmse of 24.55. But, the parameters were chosen randomly\n",
    "Now, let's tune the algorithm with 3 parameters : \n",
    "1) The number of trees \n",
    "\n",
    "2) The shrinkage parameter lambda : Typical values are 0.01 or 0.001, and the right choice can depend on the problem. Very small λ can require using a very large value of B in order to achieve good performance.\n",
    "\n",
    "3) The number of splits in each tree, which controls the complexity of the boosted ensemble (controlled with max.depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a slower learning model, by reducing the learning rate, and reducing the number of splits in each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:48.982822\ttest-rmse:47.107918 \n",
      "Multiple eval metrics are present. Will use test_rmse for early stopping.\n",
      "Will train until test_rmse hasn't improved in 50 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[280]\ttrain-rmse:12.274206\ttest-rmse:23.773617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst_slow = xgb.train(data = dtrain, \n",
    "                        max.depth=5, \n",
    "                        eta = 0.01, \n",
    "                        nthread = 2, \n",
    "                        nround = 10000, \n",
    "                        watchlist = watchlist, \n",
    "                        objective = \"reg:squarederror\", \n",
    "                        early_stopping_rounds = 50,\n",
    "                        print_every_n = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we reduced the test-rmse by 6%. The problem here : What we have done here is fit to the training set and the test set at the same time (leading to model overfit). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to work with a validation set and only at the end evaluate the model performance against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "len <- length(train.x[,1])\n",
    "idx.valid <- sample(1:len, 2*len/3)\n",
    "\n",
    "train.val.x <- train.x[idx.valid,]\n",
    "train.val.y <- train.y[idx.valid]\n",
    "\n",
    "valid.x <- train.x[-idx.valid,]\n",
    "valid.y <- train.y[-idx.valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_train = xgb.DMatrix(data = as.matrix(train.val.x), label = train.val.y )\n",
    "gb_valid = xgb.DMatrix(data = as.matrix(valid.x), label = valid.y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = list(train = gb_train, valid = gb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:49.436710\tvalid-rmse:48.084187 \n",
      "Multiple eval metrics are present. Will use valid_rmse for early stopping.\n",
      "Will train until valid_rmse hasn't improved in 50 rounds.\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[305]\ttrain-rmse:5.971423\tvalid-rmse:24.474022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst_slow = xgb.train(data= gb_train, \n",
    "                        max.depth = 10, \n",
    "                        eta = 0.01, \n",
    "                        nthread = 2, \n",
    "                        nround = 10000, \n",
    "                        watchlist = watchlist, \n",
    "                        objective = \"reg:squarederror\", \n",
    "                        early_stopping_rounds = 50,\n",
    "                        print_every_n = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "671.617282193548"
      ],
      "text/latex": [
       "671.617282193548"
      ],
      "text/markdown": [
       "671.617282193548"
      ],
      "text/plain": [
       "[1] 671.6173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "25.9155799123529"
      ],
      "text/latex": [
       "25.9155799123529"
      ],
      "text/markdown": [
       "25.9155799123529"
      ],
      "text/plain": [
       "[1] 25.91558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat_valid = predict(bst_slow, dtest)\n",
    "test_mse = mean(((y_hat_valid - test.y)^2))\n",
    "test_mse\n",
    "test_rmse = sqrt(test_mse)\n",
    "test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is higher then on the first run, but we can be confident that the improved score is not due to overfit thanks to our use of a validation set! A lower rmse isn't necessarily better if it comes at the cose of overfit, we now have more confidence in external predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the best hyper-parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>7</dd>\n",
       "\t<dt>$eta</dt>\n",
       "\t\t<dd>0.001</dd>\n",
       "\t<dt>$nthread</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'reg:squarederror'</dd>\n",
       "\t<dt>$validate_parameters</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$max\\_depth] 7\n",
       "\\item[\\$eta] 0.001\n",
       "\\item[\\$nthread] 2\n",
       "\\item[\\$objective] 'reg:squarederror'\n",
       "\\item[\\$validate\\_parameters] TRUE\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$max_depth\n",
       ":   7\n",
       "$eta\n",
       ":   0.001\n",
       "$nthread\n",
       ":   2\n",
       "$objective\n",
       ":   'reg:squarederror'\n",
       "$validate_parameters\n",
       ":   TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$max_depth\n",
       "[1] 7\n",
       "\n",
       "$eta\n",
       "[1] 0.001\n",
       "\n",
       "$nthread\n",
       "[1] 2\n",
       "\n",
       "$objective\n",
       "[1] \"reg:squarederror\"\n",
       "\n",
       "$validate_parameters\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "23.791611"
      ],
      "text/latex": [
       "23.791611"
      ],
      "text/markdown": [
       "23.791611"
      ],
      "text/plain": [
       "[1] 23.79161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max.depths = c(7, 9)\n",
    "etas = c(0.01, 0.001)\n",
    "\n",
    "best_params = 0\n",
    "best_score = 0\n",
    "\n",
    "count = 1\n",
    "\n",
    "for( depth in max.depths ) {\n",
    "    for(num in etas) {\n",
    "\n",
    "        bst_grid = xgb.train(data = gb_train, \n",
    "                                max.depth = depth, \n",
    "                                eta=num, \n",
    "                                nthread = 2, \n",
    "                                nround = 10000, \n",
    "                                watchlist = watchlist, \n",
    "                                objective = \"reg:squarederror\", \n",
    "                                early_stopping_rounds = 50, \n",
    "                                verbose=0)\n",
    "\n",
    "        if(count == 1){\n",
    "            best_params = bst_grid$params\n",
    "            best_score = bst_grid$best_score\n",
    "            count = count + 1\n",
    "            }\n",
    "        else if( bst_grid$best_score < best_score){\n",
    "            best_params = bst_grid$params\n",
    "            best_score = bst_grid$best_score\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_params\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:49.839478\tvalid-rmse:48.421314 \n",
      "Multiple eval metrics are present. Will use valid_rmse for early stopping.\n",
      "Will train until valid_rmse hasn't improved in 50 rounds.\n",
      "\n",
      "[501]\ttrain-rmse:32.446823\tvalid-rmse:34.793262 \n",
      "[1001]\ttrain-rmse:21.792664\tvalid-rmse:27.858894 \n",
      "[1501]\ttrain-rmse:15.200837\tvalid-rmse:24.959738 \n",
      "[2001]\ttrain-rmse:11.097453\tvalid-rmse:23.966742 \n",
      "Stopping. Best iteration:\n",
      "[2400]\ttrain-rmse:8.857841\tvalid-rmse:23.791611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst_tuned = xgb.train( data = gb_train, \n",
    "                        max.depth = 7, \n",
    "                        eta = 0.001, \n",
    "                        nthread = 2, \n",
    "                        nround = 10000, \n",
    "                        watchlist = watchlist, \n",
    "                        objective = \"reg:squarederror\", \n",
    "                        early_stopping_rounds = 50,\n",
    "                        print_every_n = 500)\n",
    "\n",
    "y_hat_xgb_grid = predict(bst_tuned, dtest)\n",
    "\n",
    "test_mse = mean(((y_hat_xgb_grid - test.y)^2))\n",
    "test_rmse = sqrt(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "25.7060135472519"
      ],
      "text/latex": [
       "25.7060135472519"
      ],
      "text/markdown": [
       "25.7060135472519"
      ],
      "text/plain": [
       "[1] 25.70601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now maybe try to submit to Kaggle to see if we get better on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
